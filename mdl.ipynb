{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "imagePatches = glob('C:/Users/Hanane/Downloads/IDC_regular_ps50_idx5/**/*.png', recursive=True)\n",
    "patternZero = '*class0.png'\n",
    "patternOne = '*class1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classZero = fnmatch.filter(imagePatches, patternZero)\n",
    "classOne = fnmatch.filter(imagePatches, patternOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(lowerIndex,upperIndex):\n",
    "\n",
    "    height = 50\n",
    "    width = 50\n",
    "    channels = 3\n",
    "    x = [] \n",
    "    y = [] \n",
    "    for img in imagePatches[lowerIndex:upperIndex]:\n",
    "        \n",
    "        full_size_image = cv2.imread(img)\n",
    "        \n",
    "        image = (cv2.resize(full_size_image, (width,height), interpolation=cv2.INTER_CUBIC))\n",
    "       \n",
    "        x.append(image)\n",
    "        if img in classZero:\n",
    "            y.append(0)\n",
    "        elif img in classOne:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            return\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = process_images(0,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.astype(np.float32) \n",
    "X /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\n",
    "X_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\n",
    "X_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\n",
    "X_testFlat = X_test.reshape(X_test.shape[0], X_testShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "random_under_sampler = RandomUnderSampler(ratio='majority')\n",
    "X_trainRos, Y_trainRos = random_under_sampler.fit_sample(X_trainFlat, y_train)\n",
    "X_testRos, Y_testRos = random_under_sampler.fit_sample(X_testFlat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               1843400   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 3,619,490\n",
      "Trainable params: 3,619,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "input_shape = (50, 50, 3)\n",
    "\n",
    "#Instantiate an empty model\n",
    "model = Sequential([\n",
    "Conv2D(64, (3, 3), input_shape=input_shape, padding='same', activation='relu'),\n",
    "Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "Conv2D(128, (3, 3), activation='relu', padding='same',),\n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "Flatten(),\n",
    "Dense(200, activation='relu'),\n",
    "Dense(200, activation='relu'),\n",
    "Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=180,\n",
    "    horizontal_flip=True,vertical_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,  EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=3, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_trainRosHot = to_categorical(Y_trainRos, num_classes = 2)\n",
    "Y_testRosHot = to_categorical(Y_testRos, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_trainRos)):\n",
    "    height, width, channels = 50,50,3,\n",
    "    X_trainRosReshaped = X_trainRos.reshape(len(X_trainRos),height,width,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_testRos)):\n",
    "    height, width, channels = 50,50,3\n",
    "    X_testRosReshaped = X_testRos.reshape(len(X_testRos),height,width,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hanane\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Hanane\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/193 [==============================] - 1755s 9s/step - loss: 0.5403 - accuracy: 0.7329 - val_loss: 0.4730 - val_accuracy: 0.7836\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.47299, saving model to best_model.h5\n",
      "Epoch 2/80\n",
      "194/193 [==============================] - 1743s 9s/step - loss: 0.4783 - accuracy: 0.7809 - val_loss: 0.4637 - val_accuracy: 0.7868\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.47299 to 0.46368, saving model to best_model.h5\n",
      "Epoch 3/80\n",
      "194/193 [==============================] - 1744s 9s/step - loss: 0.4442 - accuracy: 0.7996 - val_loss: 0.4193 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46368 to 0.41935, saving model to best_model.h5\n",
      "Epoch 4/80\n",
      "194/193 [==============================] - 1560s 8s/step - loss: 0.4338 - accuracy: 0.8056 - val_loss: 0.4189 - val_accuracy: 0.8145\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.41935 to 0.41893, saving model to best_model.h5\n",
      "Epoch 5/80\n",
      "194/193 [==============================] - 1407s 7s/step - loss: 0.4085 - accuracy: 0.8191 - val_loss: 0.4504 - val_accuracy: 0.7962\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.41893\n",
      "Epoch 6/80\n",
      "194/193 [==============================] - 1399s 7s/step - loss: 0.4087 - accuracy: 0.8195 - val_loss: 0.4047 - val_accuracy: 0.8201\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.41893 to 0.40473, saving model to best_model.h5\n",
      "Epoch 7/80\n",
      "194/193 [==============================] - 1403s 7s/step - loss: 0.3851 - accuracy: 0.8324 - val_loss: 0.4329 - val_accuracy: 0.8102\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.40473\n",
      "Epoch 8/80\n",
      "194/193 [==============================] - 1719s 9s/step - loss: 0.3773 - accuracy: 0.8369 - val_loss: 0.3953 - val_accuracy: 0.8253\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.40473 to 0.39531, saving model to best_model.h5\n",
      "Epoch 9/80\n",
      "194/193 [==============================] - 1745s 9s/step - loss: 0.3736 - accuracy: 0.8385 - val_loss: 0.4602 - val_accuracy: 0.7881\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.39531\n",
      "Epoch 10/80\n",
      "194/193 [==============================] - 1746s 9s/step - loss: 0.3734 - accuracy: 0.8376 - val_loss: 0.3704 - val_accuracy: 0.8412\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.39531 to 0.37039, saving model to best_model.h5\n",
      "Epoch 11/80\n",
      "194/193 [==============================] - 1746s 9s/step - loss: 0.3606 - accuracy: 0.8440 - val_loss: 0.3628 - val_accuracy: 0.8458\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.37039 to 0.36282, saving model to best_model.h5\n",
      "Epoch 12/80\n",
      "194/193 [==============================] - 1747s 9s/step - loss: 0.3580 - accuracy: 0.8461 - val_loss: 0.3623 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36282 to 0.36227, saving model to best_model.h5\n",
      "Epoch 13/80\n",
      "194/193 [==============================] - 2515s 13s/step - loss: 0.3518 - accuracy: 0.8503 - val_loss: 0.3676 - val_accuracy: 0.8442\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.36227\n",
      "Epoch 14/80\n",
      "194/193 [==============================] - 1393s 7s/step - loss: 0.3592 - accuracy: 0.8457 - val_loss: 0.3765 - val_accuracy: 0.8403\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.36227\n",
      "Epoch 15/80\n",
      "194/193 [==============================] - 1396s 7s/step - loss: 0.3406 - accuracy: 0.8548 - val_loss: 0.3467 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.36227 to 0.34665, saving model to best_model.h5\n",
      "Epoch 16/80\n",
      "194/193 [==============================] - 1397s 7s/step - loss: 0.3401 - accuracy: 0.8541 - val_loss: 0.3471 - val_accuracy: 0.8526\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34665\n",
      "Epoch 17/80\n",
      "194/193 [==============================] - 1372s 7s/step - loss: 0.3392 - accuracy: 0.8544 - val_loss: 0.3413 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34665 to 0.34129, saving model to best_model.h5\n",
      "Epoch 18/80\n",
      "194/193 [==============================] - 1299s 7s/step - loss: 0.3366 - accuracy: 0.8552 - val_loss: 0.3419 - val_accuracy: 0.8510\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.34129\n",
      "Epoch 19/80\n",
      "194/193 [==============================] - 1272s 7s/step - loss: 0.3365 - accuracy: 0.8559 - val_loss: 0.3573 - val_accuracy: 0.8418\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34129\n",
      "Epoch 20/80\n",
      "194/193 [==============================] - 1266s 7s/step - loss: 0.3334 - accuracy: 0.8564 - val_loss: 0.3366 - val_accuracy: 0.8532\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.34129 to 0.33657, saving model to best_model.h5\n",
      "Epoch 21/80\n",
      "194/193 [==============================] - 1263s 7s/step - loss: 0.3289 - accuracy: 0.8589 - val_loss: 0.4028 - val_accuracy: 0.8232\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.33657\n",
      "Epoch 22/80\n",
      "194/193 [==============================] - 1279s 7s/step - loss: 0.3284 - accuracy: 0.8599 - val_loss: 0.3311 - val_accuracy: 0.8564\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33657 to 0.33105, saving model to best_model.h5\n",
      "Epoch 23/80\n",
      "194/193 [==============================] - 1275s 7s/step - loss: 0.3233 - accuracy: 0.8621 - val_loss: 0.3430 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.33105\n",
      "Epoch 24/80\n",
      "194/193 [==============================] - 1276s 7s/step - loss: 0.3212 - accuracy: 0.8638 - val_loss: 0.3272 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.33105 to 0.32717, saving model to best_model.h5\n",
      "Epoch 25/80\n",
      "194/193 [==============================] - 1280s 7s/step - loss: 0.3179 - accuracy: 0.8653 - val_loss: 0.3756 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.32717\n",
      "Epoch 26/80\n",
      "194/193 [==============================] - 1313s 7s/step - loss: 0.3194 - accuracy: 0.8650 - val_loss: 0.3261 - val_accuracy: 0.8622\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.32717 to 0.32605, saving model to best_model.h5\n",
      "Epoch 27/80\n",
      "194/193 [==============================] - 1400s 7s/step - loss: 0.3195 - accuracy: 0.8651 - val_loss: 0.3438 - val_accuracy: 0.8489\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.32605\n",
      "Epoch 28/80\n",
      "194/193 [==============================] - 1392s 7s/step - loss: 0.3129 - accuracy: 0.8682 - val_loss: 0.3485 - val_accuracy: 0.8583\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.32605\n",
      "Epoch 29/80\n",
      "194/193 [==============================] - 1436s 7s/step - loss: 0.3142 - accuracy: 0.8676 - val_loss: 0.3165 - val_accuracy: 0.8677\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.32605 to 0.31654, saving model to best_model.h5\n",
      "Epoch 30/80\n",
      "194/193 [==============================] - 1391s 7s/step - loss: 0.3089 - accuracy: 0.8692 - val_loss: 0.3163 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.31654 to 0.31632, saving model to best_model.h5\n",
      "Epoch 31/80\n",
      "194/193 [==============================] - 1299s 7s/step - loss: 0.3115 - accuracy: 0.8688 - val_loss: 0.3442 - val_accuracy: 0.8544\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.31632\n",
      "Epoch 32/80\n",
      "194/193 [==============================] - 1434s 7s/step - loss: 0.3071 - accuracy: 0.8698 - val_loss: 0.3214 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.31632\n",
      "Epoch 33/80\n",
      "194/193 [==============================] - 1464s 8s/step - loss: 0.3068 - accuracy: 0.8703 - val_loss: 0.3196 - val_accuracy: 0.8624\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.31632\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 80\n",
    "training = model.fit_generator(datagen.flow(X_trainRosReshaped,Y_trainRosHot,batch_size=batch_size),steps_per_epoch=len(X_trainRosReshaped) / batch_size, epochs=epochs,validation_data=(X_testRosReshaped, Y_testRosHot), verbose=1, callbacks=[early_stopping_monitor, model_checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
